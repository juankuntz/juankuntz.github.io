[{"authors":null,"categories":null,"content":"I am a Research Fellow working with Adam Johansen as part of the Warwick Machine Learning Group and the Department of Statistics at the University of Warwick. I develop tools for probabilistic machine learning, Bayesian inference, and computational statistics by combining concepts and techniques from optimization and Monte Carlo; see here for a recent example. In the past, I worked on Markov processes and numerical methods for the analysis thereof. I have also been writing a book on Markov chains, see here for the latest draft.\n  Short CV.\n","date":1646092800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646092800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Research Fellow working with Adam Johansen as part of the Warwick Machine Learning Group and the Department of Statistics at the University of Warwick. I develop tools for probabilistic machine learning, Bayesian inference, and computational statistics by combining concepts and techniques from optimization and Monte Carlo; see here for a recent example.","tags":null,"title":"Juan Kuntz","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://juankuntz.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Juan Kuntz","Adam M. Johansen"],"categories":null,"content":"","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"cf97010b48ad534a40e5be099833e4ed","permalink":"https://juankuntz.github.io/publication/parem/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/publication/parem/","section":"publication","summary":"Building on [(Neal and Hinton, 1998)](https://link.springer.com/chapter/10.1007/978-94-011-5014-9_12), where the problem tackled by EM is recast as the optimization of a free energy functional on an infinite-dimensional space, we obtain three practical particle-based alternatives to EM applicable to broad classes of models. All three are derived through straightforward discretizations of gradient flows associated with the functional. The novel algorithms scale well to high-dimensional settings and outperform existing state-of-the-art methods in numerical experiments.","tags":["Machine learning","Bayesian inference","Monte Carlo","Optimization"],"title":"Scalable particle-based alternatives to EM","type":"publication"},{"authors":["Juan Kuntz","Francesca R. Crucinio","Adam M. Johansen"],"categories":null,"content":"","date":1643673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643673600,"objectID":"7cc2553b26087bbd0bf4ecd936cfaaff","permalink":"https://juankuntz.github.io/publication/pf/","publishdate":"2022-02-01T00:00:00Z","relpermalink":"/publication/pf/","section":"publication","summary":"We introduce a class of Monte Carlo estimators that aim to overcome the rapid growth of variance with dimension often observed for standard estimators by exploiting the target's independence structure. We identify the most basic incarnations of these estimators with a class of generalized U-statistics and thus establish their unbiasedness, consistency, and asymptotic normality. Moreover, we show that they obtain the minimum possible variance amongst a broad class of estimators, and we investigate their computational cost and delineate the settings in which they are most efficient. We exemplify the merger of these estimators with other well known Monte Carlo estimators so as to better adapt the latter to the target's independence structure and improve their performance. We do this via three simple mergers:: one with importance sampling, another with importance sampling squared, and a final one with pseudo-marginal Metropolis–Hastings. In all cases, we show that the resulting estimators are well founded and achieve lower variances than their standard counterparts. Lastly, we illustrate the various variance reductions through several examples.","tags":["Monte Carlo","Bayesian inference","Numerical methods"],"title":"Product-form estimators: exploiting independence to scale up Monte Carlo","type":"publication"},{"authors":["Juan Kuntz","Francesca R. Crucinio","Adam M. Johansen"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"f7f1b9aff964c077098f5246afa832b7","permalink":"https://juankuntz.github.io/publication/dacclt/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/dacclt/","section":"publication","summary":"We revisit the divide-and-conquer sequential Monte Carlo (DaC-SMC) algorithm and firmly establish it as a well-founded method by showing that it possesses the same basic properties as conventional sequential Monte Carlo (SMC) algorithms do. In particular, we derive pertinent laws of large numbers, $L^p$ inequalities, and central limit theorems; and we characterize the bias in the normalized estimates produced by the algorithm and argue the absence thereof in the unnormalized ones. We further consider its practical implementation and several interesting variants; obtain expressions for its globally and locally optimal intermediate targets, auxiliary measures, and proposal kernels; and show that, in comparable conditions, DaC-SMC proves more statistically efficient than its direct SMC analogue. We close the paper with a discussion of our results, open questions, and future research directions. ","tags":["Monte Carlo","Bayesian inference","Numerical methods"],"title":"The divide-and-conquer sequential Monte Carlo algorithm: theoretical properties and limit theorems","type":"publication"},{"authors":["Juan Kuntz","Philipp Thomas","Guy-Bart Stan","Mauricio Barahona"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"6208e552a16377882e7836b76add9d13","permalink":"https://juankuntz.github.io/publication/clp/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/clp/","section":"publication","summary":"We study a class of countably infinite linear programs (CILPs) whose feasible sets are bounded subsets of appropriately defined spaces of measures. The optimal value, optimal points, and minimal points of these CILPs can be approximated by solving finite-dimensional linear programs. We show how to construct finite-dimensional programs that lead to approximations with easy-to-evaluate error bounds, and we prove that the errors converge to zero as the size of the finite-dimensional programs approaches that of the original problem. We discuss the use of our methods in the computation of the stationary distributions, occupation measures, and exit distributions of Markov chains.","tags":["Optimization","Numerical methods"],"title":"Approximations of Countably Infinite Linear Programs over Bounded Measure Spaces","type":"publication"},{"authors":["Juan Kuntz","Philipp Thomas","Guy-Bart Stan","Mauricio Barahona"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"34de99b5406baa0713007a0bf025eb95","permalink":"https://juankuntz.github.io/publication/stctmc/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/stctmc/","section":"publication","summary":"Computing the stationary distributions of a continuous-time Markov chain (CTMC) involves solving a set of linear equations. In most cases of interest, the number of equations is infinite or too large, and the equations cannot be solved analytically or numerically. Several approximation schemes overcome this issue by truncating the state space to a manageable size. In this review, we first give a comprehensive theoretical account of the stationary distributions and their relation to the long-term behaviour of CTMCs that is readily accessible to non-experts and free of irreducibility assumptions made in standard texts. We then review truncation-based approximation schemes for CTMCs with infinite state spaces paying particular attention to the schemes' convergence and the errors they introduce, and we illustrate their performance with an example of a stochastic reaction network of relevance in biology and chemistry. We conclude by elaborating on computational trade-offs associated with error control and several open questions.","tags":["Markov processes","Numerical methods","Optimization"],"title":"Stationary Distributions of Continuous-Time Markov Chains: A Review of Theory and Truncation-Based Approximations","type":"publication"},{"authors":["Juan Kuntz"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"5b07b7771a1b53efe1b5754b1876926c","permalink":"https://juankuntz.github.io/publication/mcbook/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/mcbook/","section":"publication","summary":"A book draft on Markov chains, see preface for more information.","tags":["Markov processes"],"title":"Markov chains revisited","type":"publication"},{"authors":["Juan Kuntz","Michela Ottobre","Andrew M. Stuart"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"0f738b6f993264cf809ec2e6f144abca","permalink":"https://juankuntz.github.io/publication/dlrwm/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/dlrwm/","section":"publication","summary":"The Random Walk Metropolis (RWM) algorithm is a Metropolis–Hastings Markov Chain Monte Carlo algorithm designed to sample from a given target distribution $\\pi^N$ with Lebesgue density on $\\mathbb{R}^N$. Like any other Metropolis–Hastings algorithm, RWM constructs a Markov chain by randomly proposing a new position (the “proposal move”), which is then accepted or rejected according to a rule which makes the chain reversible with respect to $\\pi^N$. When the dimension N is large, a key question is to determine the optimal scaling with N of the proposal variance: if the proposal variance is too large, the algorithm will reject the proposed moves too often; if it is too small, the algorithm will explore the state space too slowly. Determining the optimal scaling of the proposal variance gives a measure of the cost of the algorithm as well. One approach to tackle this issue, which we adopt here, is to derive diffusion limits for the algorithm. Such an approach has been proposed in the seminal papers (Ann. Appl. Probab. 7 (1) (1997) 110–120; J. R. Stat. Soc. Ser. B. Stat. Methodol. 60 (1) (1998) 255–268). In particular, in (Ann. Appl. Probab. 7 (1) (1997) 110–120) the authors derive a diffusion limit for the RWM algorithm under the two following assumptions: (i) the algorithm is started in stationarity; (ii) the target measure $\\pi^N$ is in product form. The present paper considers the situation of practical interest in which both assumptions (i) and (ii) are removed. That is (a) we study the case (which occurs in practice) in which the algorithm is started out of stationarity and (b) we consider target measures which are in non-product form. Roughly speaking, we consider target measures that admit a density with respect to Gaussian; such measures arise in Bayesian nonparametric statistics and in the study of conditioned diffusions. We prove that, out of stationarity, the optimal scaling for the proposal variance is $\\mathcal{O}(N^{-1})$, as it is in stationarity. In this optimal scaling, a diffusion limit is obtained and the cost of reaching and exploring the invariant measure scales as $\\mathcal{O}(N)$. Notice that the optimal scaling in and out of stationatity need not be the same in general, and indeed they differ e.g. in the case of the MALA algorithm (Stoch. Partial Differ. Equ. Anal Comput. 6 (3) (2018) 446–499). More importantly, our diffusion limit is given by a stochastic PDE, coupled to a scalar ordinary differential equation; such an ODE gives a measure of how far from stationarity the process is and can therefore be taken as an indicator of convergence. In this sense, this paper contributes understanding to the old-standing problem of monitoring convergence of MCMC algorithms.","tags":["Monte Carlo","Numerical methods"],"title":"Diffusion limit for the random walk Metropolis algorithm out of stationarity","type":"publication"},{"authors":["Juan Kuntz","Philipp Thomas","Guy-Bart Stan","Mauricio Barahona"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"6d1475d6e8b1c00b8d349eb8570290fc","permalink":"https://juankuntz.github.io/publication/bcme/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/bcme/","section":"publication","summary":"The stochastic dynamics of biochemical networks are usually modeled with the chemical master equation (CME). The stationary distributions of CMEs are seldom solvable analytically, and numerical methods typically produce estimates with uncontrolled errors. Here, we introduce mathematical programming approaches that yield approximations of these distributions with computable error bounds which enable the verification of their accuracy. First, we use semidefinite programming to compute increasingly tighter upper and lower bounds on the moments of the stationary distributions for networks with rational propensities. Second, we use these moment bounds to formulate linear programs that yield convergent upper and lower bounds on the stationary distributions themselves, their marginals, and stationary averages. The bounds obtained also provide a computational test for the uniqueness of the distribution. In the unique case, the bounds form an approximation of the stationary distribution with a computable bound on its error. In the nonunique case, our approach yields converging approximations of the ergodic distributions. We illustrate our methodology through several biochemical examples taken from the literature: Schlögl’s model for a chemical bifurcation, a two-dimensional toggle switch, a model for bursty gene expression, and a dimerization model with multiple stationary distributions.","tags":["Optimization","Markov processes","Numerical methods"],"title":"Bounding the stationary distributions of the chemical master equation via mathematical programming","type":"publication"},{"authors":["Juan Kuntz","Philipp Thomas","Guy-Bart Stan","Mauricio Barahona"],"categories":null,"content":"","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551398400,"objectID":"2a405ca3a133b1ade05debf3577c320f","permalink":"https://juankuntz.github.io/publication/etfsp/","publishdate":"2019-03-01T00:00:00Z","relpermalink":"/publication/etfsp/","section":"publication","summary":"We introduce the exit time finite state projection (ETFSP) scheme, a truncation-based method that yields approximations to the exit distribution and occupation measure associated with the time of exit from a domain (i.e., the time of first passage to the complement of the domain) of time-homogeneous continuous-time Markov chains. We prove that (i) the computed approximations bound the measures from below; (ii) the total variation distances between the approximations and the measures decrease monotonically as states are added to the truncation; and (iii) the scheme converges, in the sense that, as the truncation tends to the entire state space, the total variation distances tend to zero. Furthermore, we give a computable bound on the total variation distance between the exit distribution and its approximation, and we delineate the cases in which the bound is sharp. We also revisit the related finite state projection scheme and give a comprehensive account of its theoretical properties. We demonstrate the use of the ETFSP scheme by applying it to two biological examples: the computation of the first passage time associated with the expression of a gene, and the fixation times of competing species subject to demographic noise.","tags":["Markov Processes","Numerical methods"],"title":"The exit time finite state projection scheme: bounding exit distributions and occupation measures of continuous-time Markov chains","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}   Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://juankuntz.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Juan Kuntz","Michela Ottobre","Andrew M. Stuart"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"b1e5933d901c7e2aec154de5b527b260","permalink":"https://juankuntz.github.io/publication/dlmala/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/publication/dlmala/","section":"publication","summary":"The Metropolis-Adjusted Langevin Algorithm (MALA) is a Markov Chain Monte Carlo method which creates a Markov chain reversible with respect to a given target distribution, $\\pi^N$, with Lebesgue density on $\\mathbb{R}^N$; it can hence be used to approximately sample the target distribution. When the dimension $N$ is large a key question is to determine the computational cost of the algorithm as a function of $N$. The measure of efficiency that we consider in this paper is the expected squared jumping distance (ESJD), introduced in Roberts et al. (Ann Appl Probab 7(1):110–120, 1997). To determine how the cost of the algorithm (in terms of ESJD) increases with dimension $N$, we adopt the widely used approach of deriving a diffusion limit for the Markov chain produced by the MALA algorithm. We study this problem for a class of target measures which is not in product form and we address the situation of practical relevance in which the algorithm is started out of stationarity. We thereby significantly extend previous works which consider either measures of product form, when the Markov chain is started out of stationarity, or non-product measures (defined via a density with respect to a Gaussian), when the Markov chain is started in stationarity. In order to work in this non-stationary and non-product setting, significant new analysis is required. In particular, our diffusion limit comprises a stochastic PDE coupled to a scalar ordinary differential equation which gives a measure of how far from stationarity the process is. The family of non-product target measures that we consider in this paper are found from discretization of a measure on an infinite dimensional Hilbert space; the discretised measure is defined by its density with respect to a Gaussian random field. The results of this paper demonstrate that, in the non-stationary regime, the cost of the algorithm is of $\\mathcal{O}(N^{1/2})$ in contrast to the stationary regime, where it is of $\\mathcal{O}(N^{1/3})$.","tags":["Monte Carlo","Numerical methods"],"title":"Non-stationary phase of the MALA algorithm","type":"publication"},{"authors":["Juan Kuntz"],"categories":null,"content":"","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"0f40cf545adf79432be77d9037b7794b","permalink":"https://juankuntz.github.io/publication/thesis/","publishdate":"2017-10-01T00:00:00Z","relpermalink":"/publication/thesis/","section":"publication","summary":"This thesis is a monograph on Markov chains and deterministic approximation schemes that enable the quantitative analysis thereof. We present schemes that yield approximations of the time-varying law of a Markov chain, of its stationary distributions, and of the exit distributions and occupation measures associated with its exit times. In practice, our schemes reduce to solving systems of linear ordinary differential equations, linear programs, and semidefinite programs. We focus on the theoretical aspects of these schemes, proving convergence and providing computable error bounds for most of them. To a lesser extent, we study their practical use, applying them to a variety of examples and discussing the numerical issues that arise in their implementation.","tags":["Markov processes","Optimization","Numerical methods"],"title":"Deterministic approximation schemes with computable errors for the distributions of Markov chains","type":"publication"},{"authors":["Juan Kuntz","Michela Ottobre","Guy-Bart Stan","Mauricio Barahona"],"categories":null,"content":"","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"a2c13784ee106cc779e76e27f4d07eb0","permalink":"https://juankuntz.github.io/publication/bsde/","publishdate":"2016-12-01T00:00:00Z","relpermalink":"/publication/bsde/","section":"publication","summary":"We introduce an algorithm based on semidefinite programming that yields increasing (resp., decreasing) sequences of lower (resp., upper) bounds on polynomial stationary averages of diffusions with polynomial drift vector and diffusion coefficients. The bounds are obtained by optimizing an objective, determined by the stationary average of interest, over the set of real vectors defined by certain linear equalities and semidefinite inequalities which are satisfied by the moments of any stationary measure of the diffusion. We exemplify the use of the approach through several applications: a Bayesian inference problem; the computation of Lyapunov exponents of linear ordinary differential equations perturbed by multiplicative white noise; and a reliability problem from structural mechanics. Additionally, we prove that the bounds converge to the infimum and supremum of the set of stationary averages for certain SDEs associated with the computation of the Lyapunov exponents, and we provide numerical evidence of convergence in more general settings.","tags":["Optimization","Markov processes","Numerical methods"],"title":"Bounding Stationary Averages of Polynomial Diffusions via Semidefinite Programming","type":"publication"},{"authors":null,"categories":null,"content":"Main blurb, blablabla\nCode: We have written interactive Colab notebooks illustrating the application of our algorithms and reproducing our results. There’s one per example in paper:\n Toy hierachical model Bayesian logistic regression Bayesian neural network  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"25875744b00ceaebbc80db93e6492a89","permalink":"https://juankuntz.github.io/project/parem/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/parem/","section":"project","summary":"Summary, blablabla","tags":null,"title":"Scalable particle-based alternatives to EM","type":"project"},{"authors":["Juan Kuntz","Diego Oyarzun","Guy-Bart Stan"],"categories":null,"content":"","date":1404172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404172800,"objectID":"100fa4d98ec63c898005d7ef70a680a7","permalink":"https://juankuntz.github.io/publication/tsschap/","publishdate":"2014-07-01T00:00:00Z","relpermalink":"/publication/tsschap/","section":"publication","summary":"Model reduction techniques often prove indispensable in the analysis of physical and biological phenomena. A succesful reduction technique can substantially simplify a model while retaining all of its pertinent features. In metabolic networks, metabolites evolve on much shorter time scales than the catalytic enzymes. In this chapter, we exploit this discrepancy to justify the reduction via time scale separation of a class of models of metabolic networks under genetic regulation . We formalise the concept of a metabolic network and employ Tikhonov's Theorem for singularly perturbed systems. We demonstrate the applicability of our result by using it to address a problem in metabolic engineering: the genetic control of branched metabolic pathways. We conclude by providing guidelines on how to generalise our result to larger classes of networks.","tags":["Systems biology"],"title":"Model Reduction of Genetic-Metabolic Networks via Time Scale Separation","type":"publication"}]